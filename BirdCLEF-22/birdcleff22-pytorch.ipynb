{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchvision\nimport torchaudio\nfrom torchvision import transforms\nimport torchvision.models as models\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data.datapipes.iter import FileLister\nfrom torch.optim import lr_scheduler\nimport numpy as np\nimport pandas as pd\nimport os\nimport librosa\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score\nimport time\nimport copy\nfrom tqdm import tqdm\nfrom math import ceil\nimport random","metadata":{"execution":{"iopub.status.busy":"2022-08-10T07:24:34.543592Z","iopub.execute_input":"2022-08-10T07:24:34.544372Z","iopub.status.idle":"2022-08-10T07:24:38.473003Z","shell.execute_reply.started":"2022-08-10T07:24:34.544195Z","shell.execute_reply":"2022-08-10T07:24:38.471550Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_folder = \"../input/birdclef-2022/train_audio\"\nmeta_file_path = \"../input/birdclef-2022/train_metadata.csv\"","metadata":{"execution":{"iopub.status.busy":"2022-08-10T07:24:38.476277Z","iopub.execute_input":"2022-08-10T07:24:38.477328Z","iopub.status.idle":"2022-08-10T07:24:38.487146Z","shell.execute_reply.started":"2022-08-10T07:24:38.477285Z","shell.execute_reply":"2022-08-10T07:24:38.485886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"meta_data = pd.read_csv(meta_file_path)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T07:24:38.489338Z","iopub.execute_input":"2022-08-10T07:24:38.489863Z","iopub.status.idle":"2022-08-10T07:24:38.594697Z","shell.execute_reply.started":"2022-08-10T07:24:38.489820Z","shell.execute_reply":"2022-08-10T07:24:38.593605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = list(meta_data['primary_label'].unique())\nprint(len(classes))\nprint(classes)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T07:24:41.700194Z","iopub.execute_input":"2022-08-10T07:24:41.700887Z","iopub.status.idle":"2022-08-10T07:24:41.716214Z","shell.execute_reply.started":"2022-08-10T07:24:41.700848Z","shell.execute_reply":"2022-08-10T07:24:41.714883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SAMPLE_RATE = 44100\nNUM_SAMPLES = SAMPLE_RATE*5\nN_MELS = 431\nHOP_LENGTH = 512\nN_FFT = 4096\nWINDOW = 1764\nBATCH_SIZE = 64\nEPOCHS = 5\nLEARNING_RATE = 0.001\nWORKERS = 0\nNUM_CLASSES = 152\nNUM_FOLDS = 10\n\nNEED_MORE = 50\nNUM_AUGS = 4\n\nMIN_NOISE = 0.1\nMAX_NOISE = 0.4\nMIN_PITCH_SCALE = -2\nMAX_PITCH_SCALE = 2\nMIN_GAIN = 1\nMAX_GAIN = 1.5\n\nIMAGE_RESIZE = 215","metadata":{"execution":{"iopub.status.busy":"2022-08-10T07:24:44.710805Z","iopub.execute_input":"2022-08-10T07:24:44.711983Z","iopub.status.idle":"2022-08-10T07:24:44.723379Z","shell.execute_reply.started":"2022-08-10T07:24:44.711923Z","shell.execute_reply":"2022-08-10T07:24:44.722117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aug_num_bird_samples = []\nclasses_need_augmentation = []\nfor class_name in classes:\n    num = (meta_data.primary_label == class_name).sum()\n    if num < NEED_MORE:\n        classes_need_augmentation.append(class_name)\n        aug_num_bird_samples.append(num)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T07:24:46.630328Z","iopub.execute_input":"2022-08-10T07:24:46.631613Z","iopub.status.idle":"2022-08-10T07:24:46.817806Z","shell.execute_reply.started":"2022-08-10T07:24:46.631563Z","shell.execute_reply":"2022-08-10T07:24:46.816825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classes_need_augmentation)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T07:24:47.940298Z","iopub.execute_input":"2022-08-10T07:24:47.941166Z","iopub.status.idle":"2022-08-10T07:24:47.947477Z","shell.execute_reply.started":"2022-08-10T07:24:47.941125Z","shell.execute_reply":"2022-08-10T07:24:47.946204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(aug_num_bird_samples))\nprint(len(classes_need_augmentation))","metadata":{"execution":{"iopub.status.busy":"2022-08-10T07:24:49.380079Z","iopub.execute_input":"2022-08-10T07:24:49.380742Z","iopub.status.idle":"2022-08-10T07:24:49.386166Z","shell.execute_reply.started":"2022-08-10T07:24:49.380704Z","shell.execute_reply":"2022-08-10T07:24:49.385093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2022-08-10T07:24:50.530225Z","iopub.execute_input":"2022-08-10T07:24:50.530967Z","iopub.status.idle":"2022-08-10T07:24:51.579423Z","shell.execute_reply.started":"2022-08-10T07:24:50.530928Z","shell.execute_reply":"2022-08-10T07:24:51.578266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-08-10T07:24:52.440371Z","iopub.execute_input":"2022-08-10T07:24:52.441219Z","iopub.status.idle":"2022-08-10T07:24:52.513640Z","shell.execute_reply.started":"2022-08-10T07:24:52.441177Z","shell.execute_reply":"2022-08-10T07:24:52.512443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BirdDataset(Dataset):\n    def __init__(self, train_folder, transformation, augmentations, sample_rate, num_samples, device):\n        super().__init__()\n        self.device = device\n        self.train_files_list = []#list(FileLister(root=train_folder, recursive=True))\n        self.transformation = transformation\n        self.augmentations = augmentations\n        self.sample_rate = sample_rate\n        self.num_samples = num_samples\n        self._downsample()\n        self._add_filenames_for_generation()\n        \n    def _downsample(self):\n        for _, class_name in enumerate(classes):\n            class_train_files = list(FileLister(root=train_folder+'/'+class_name))\n            if len(class_train_files) > NEED_MORE:\n                random.shuffle(list(class_train_files))\n                for _, f_name in enumerate(class_train_files[: NEED_MORE]):\n                    self.train_files_list.append(f_name)\n            else:\n                for _, f_name in enumerate(class_train_files):\n                    self.train_files_list.append(f_name)\n                \n    \n    def _add_filenames_for_generation(self):\n        # loop by classes need more data\n        for idx, class_name in enumerate(classes_need_augmentation):\n            #Get number of files to be generated per original files\n            num_orig_files = aug_num_bird_samples[idx]\n            num_gen_files = NEED_MORE - num_orig_files\n            num_gen_files_per_orig = ceil( num_gen_files/num_orig_files ) \n            \n            class_train_files = list(FileLister(root=train_folder+'/'+class_name))\n            #Loop by original file name and add new filename and corresponding classname\n            for count in range(num_orig_files):\n                for i in range(num_gen_files_per_orig):\n                    new_filename = class_train_files[count] + 'augment'\n                    self.train_files_list.append(new_filename)\n        \n    def __len__(self):\n        self.total_train_file = len(self.train_files_list)\n        return self.total_train_file\n        \n    def list_all_files(self):\n        return list(self.train_files_list)\n    \n    def _resample(self, signal, sr):\n        if sr != self.sample_rate: \n            resampler = torchaudio.transforms.Resample(sr, self.sample_rate)\n            signal = resampler(signal)\n        return signal\n    \n    def _mix_channels(self, signal):\n        if signal.shape[0] > 1:\n            signal = torch.mean(signal, dim=0, keepdim=True)\n        return signal\n    \n    def _right_padding(self,signal):\n        if signal.shape[1] < self.num_samples:\n            num_missing_samples = self.num_samples - signal.shape[1]\n            last_dim_pad = (0, num_missing_samples)\n            signal = torch.nn.functional.pad(signal, last_dim_pad)\n        return signal\n        \n    def _crop(self, signal):\n        if signal.shape[1] > self.num_samples:\n            signal = signal[:, :self.num_samples]\n        return signal\n    \n    def _aug_white_noise(self,signal):\n        scale = np.random.uniform(MIN_NOISE, MAX_NOISE)\n        noise = np.random.normal(0, signal.std(), signal.size)\n        aug_sig = signal + noise*scale\n        return aug_sig\n        \n    def __getitem__(self,index):\n        filename = self.train_files_list[index]\n        temp = filename.split(os.sep)\n        label = temp[-2]\n        if_aug = False\n        if 'augment' in filename:\n            if_aug = True\n            filename = filename[:-7]\n        label = classes.index(label)\n        #label = label.to(self.device)\n        signal, sr = torchaudio.load(filename)\n        signal = self._resample(signal, sr)\n        signal = signal.to(self.device)\n        signal = self._mix_channels(signal)\n        signal = self._right_padding(signal)\n        signal = self._crop(signal)\n        if if_aug == True:\n            #signal = self._aug_white_noise(signal)\n            signal = self.augmentations(signal)\n        signal = self.transformation(signal)\n        signal = torch.stack([signal[0],signal[0],signal[0]])\n        return signal,label","metadata":{"execution":{"iopub.status.busy":"2022-08-10T07:24:54.547875Z","iopub.execute_input":"2022-08-10T07:24:54.550807Z","iopub.status.idle":"2022-08-10T07:24:54.575730Z","shell.execute_reply.started":"2022-08-10T07:24:54.550761Z","shell.execute_reply":"2022-08-10T07:24:54.574697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pitch_scale = np.random.randint(MIN_PITCH_SCALE, MAX_PITCH_SCALE)\npitch_scaler = torchaudio.transforms.PitchShift(sample_rate= SAMPLE_RATE, n_steps=pitch_scale)\n\ngain_scale = np.random.uniform(MIN_GAIN, MAX_GAIN)\ngain_scaler = torchaudio.transforms.Vol(gain=gain_scale)\n\naug_transfms = [pitch_scaler.to(device),gain_scaler.to(device)]\n\naugmentations = transforms.Compose(\n[\n    transforms.RandomChoice(aug_transfms)\n])","metadata":{"execution":{"iopub.status.busy":"2022-08-10T07:24:56.150231Z","iopub.execute_input":"2022-08-10T07:24:56.150840Z","iopub.status.idle":"2022-08-10T07:24:59.281187Z","shell.execute_reply.started":"2022-08-10T07:24:56.150803Z","shell.execute_reply":"2022-08-10T07:24:59.280160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mel_spectrogram = torchaudio.transforms.MelSpectrogram(sample_rate=SAMPLE_RATE, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mels=N_MELS)\n\nmean = np.array([0.5])\nstd = np.array([0.5])\ndata_transforms = transforms.Compose(\n[\n    mel_spectrogram.to(device),\n    transforms.ToPILImage(),\n    transforms.Resize([IMAGE_RESIZE, IMAGE_RESIZE]).to(device),\n    transforms.ToTensor(),\n    transforms.Normalize(mean, std).to(device)\n])","metadata":{"execution":{"iopub.status.busy":"2022-08-10T07:24:59.283236Z","iopub.execute_input":"2022-08-10T07:24:59.283985Z","iopub.status.idle":"2022-08-10T07:24:59.318744Z","shell.execute_reply.started":"2022-08-10T07:24:59.283941Z","shell.execute_reply":"2022-08-10T07:24:59.317755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bird_cleff_ds = BirdDataset(train_folder, data_transforms, augmentations, SAMPLE_RATE, NUM_SAMPLES, device)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T07:24:59.320065Z","iopub.execute_input":"2022-08-10T07:24:59.320473Z","iopub.status.idle":"2022-08-10T07:25:04.040180Z","shell.execute_reply.started":"2022-08-10T07:24:59.320405Z","shell.execute_reply":"2022-08-10T07:25:04.039168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bird_cleff_ds.__len__()","metadata":{"execution":{"iopub.status.busy":"2022-08-10T07:25:04.042419Z","iopub.execute_input":"2022-08-10T07:25:04.043229Z","iopub.status.idle":"2022-08-10T07:25:04.050176Z","shell.execute_reply.started":"2022-08-10T07:25:04.043190Z","shell.execute_reply":"2022-08-10T07:25:04.049193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_size = int(0.8 * bird_cleff_ds.__len__())\nval_size = bird_cleff_ds.__len__() - train_size\ntrainset, valset = torch.utils.data.random_split(bird_cleff_ds, [train_size, val_size])","metadata":{"execution":{"iopub.status.busy":"2022-08-10T07:25:47.286508Z","iopub.execute_input":"2022-08-10T07:25:47.287481Z","iopub.status.idle":"2022-08-10T07:25:47.293893Z","shell.execute_reply.started":"2022-08-10T07:25:47.287419Z","shell.execute_reply":"2022-08-10T07:25:47.292957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(trainset), len(valset)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T07:25:48.405248Z","iopub.execute_input":"2022-08-10T07:25:48.406247Z","iopub.status.idle":"2022-08-10T07:25:48.413010Z","shell.execute_reply.started":"2022-08-10T07:25:48.406202Z","shell.execute_reply":"2022-08-10T07:25:48.411811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=WORKERS)\nvalloader  = DataLoader(valset, batch_size=BATCH_SIZE, num_workers=WORKERS)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T07:25:49.505368Z","iopub.execute_input":"2022-08-10T07:25:49.506660Z","iopub.status.idle":"2022-08-10T07:25:49.512398Z","shell.execute_reply.started":"2022-08-10T07:25:49.506610Z","shell.execute_reply":"2022-08-10T07:25:49.511201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(trainloader), len(valloader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataiter = iter(trainloader)\nsample = dataiter.next()\ns,l = sample","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_spectrogram(spec, xmax=None):\n    fig, axs = plt.subplots(1, 1, figsize=(10,4))\n    axs.set_title(\"Mel-Spectrogram\")\n    axs.set_ylabel(\"mel-freq\")\n    axs.set_xlabel(\"frame\")\n    im = axs.imshow(librosa.power_to_db(spec), origin=\"lower\", aspect=\"auto\")\n    if xmax:\n        axs.set_xlim((0, xmax))\n    fig.colorbar(im, ax=axs)\n    plt.show(block=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_spectrogram(s[14][0].cpu())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del dataiter","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del s\ndel l","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef get_model():\n    model = models.resnet50(pretrained=True)\n    num_ftrs_last_layer = model.fc.in_features\n    \n    model.fc = nn.Linear(num_ftrs_last_layer, NUM_CLASSES)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-08-10T07:35:07.706337Z","iopub.execute_input":"2022-08-10T07:35:07.707068Z","iopub.status.idle":"2022-08-10T07:35:07.712876Z","shell.execute_reply.started":"2022-08-10T07:35:07.707030Z","shell.execute_reply":"2022-08-10T07:35:07.711626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from torch.torchsummary import summary\n\nmodel = get_model()\nmodel = model.to(device)\nprint(model)\n#summary(model, input_size=(64, 3, 215, 215))","metadata":{"execution":{"iopub.status.busy":"2022-08-10T07:35:09.065301Z","iopub.execute_input":"2022-08-10T07:35:09.065931Z","iopub.status.idle":"2022-08-10T07:35:14.974509Z","shell.execute_reply.started":"2022-08-10T07:35:09.065896Z","shell.execute_reply":"2022-08-10T07:35:14.973353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n\n#lr_step_sched = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T07:35:23.145813Z","iopub.execute_input":"2022-08-10T07:35:23.146179Z","iopub.status.idle":"2022-08-10T07:35:23.154263Z","shell.execute_reply.started":"2022-08-10T07:35:23.146147Z","shell.execute_reply":"2022-08-10T07:35:23.153385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train and eval funcs:\n\ndef train_func(trainloader, model, optimizer, criterion):\n    \n    total_loss = 0.0\n    model.train()\n    \n    #TQDM progress bar\n    loop = tqdm(trainloader, total=len(trainloader), leave=False)\n    \n    for mel_specs, labels in loop:\n        mel_specs = mel_specs.to(device)\n        labels = labels.to(device)\n\n        optimizer.zero_grad()\n        logits = model(mel_specs)\n        loss = criterion(logits, labels)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n        loop.set_postfix(loss = loss.item())\n  \n    return total_loss/ len(trainloader)\n\ndef eval_func(valloader, model, criterion):\n    total_loss = 0.0\n    model.eval()\n    \n    #TQDM progress bar\n    loop = tqdm(valloader, total=len(valloader), leave=False)\n    \n\n    for mel_specs, labels in loop:\n        mel_specs = mel_specs.to(device)\n        labels = labels.to(device)\n\n        logits = model(mel_specs)\n        loss = criterion(logits, labels)\n\n        total_loss += loss.item()\n        loop.set_postfix(loss = loss.item())\n\n    return total_loss/ len(valloader)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T08:18:01.457783Z","iopub.execute_input":"2022-08-10T08:18:01.458216Z","iopub.status.idle":"2022-08-10T08:18:01.469105Z","shell.execute_reply.started":"2022-08-10T08:18:01.458181Z","shell.execute_reply":"2022-08-10T08:18:01.467724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Training\n\nbest_val_loss = np.Inf\n\nfor i in range(EPOCHS):\n  train_loss = train_func( trainloader, model, optimizer, criterion)\n  val_loss = eval_func(valloader, model, criterion)\n\n  if val_loss < best_val_loss:\n    torch.save(model.state_dict(), 'bird_cleff_fine_tuned_model.pt')\n    print(\"Model saved!\")\n    best_val_loss = val_loss\n\n  print(f\"Epoch={i+1}, train_loss= {train_loss}, val_loss={val_loss}\")","metadata":{"execution":{"iopub.status.busy":"2022-08-10T08:18:01.472240Z","iopub.execute_input":"2022-08-10T08:18:01.472709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}